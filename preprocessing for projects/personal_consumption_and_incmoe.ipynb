{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc=pd.read_csv('C:/Users/ttodd/OneDrive/Desktop/capstone/final data/PCE_ALL_AREAS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_list=[\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "  \"Connecticut\",\"Delaware\",'District of Columbia',\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "pc=pc.loc[pc['GeoName'].isin(state_list),:]\n",
    "pc_percap=pd.read_csv('C:/Users/ttodd/OneDrive/Desktop/capstone/final data/PCPCE_ALL_AREAS.csv')\n",
    "pc_percap=pc_percap.loc[pc_percap['GeoName'].isin(state_list),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_column=['GeoName','Description','1997', '1998',\n",
    "       '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007',\n",
    "       '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015','2016']\n",
    "pc_percap=pc_percap.loc[:,cleaned_column]\n",
    "melted_df=pc_percap.melt(id_vars=['Description','GeoName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pivot_pc_df(df):\n",
    "    grouped_df=df.groupby(['Description'])\n",
    "    count=0\n",
    "    for name, group in grouped_df:\n",
    "        group=group.drop('Description',axis=1)\n",
    "        group.columns=['GeoName','year','pce'+name]\n",
    "        if count==0:\n",
    "            final_df=group\n",
    "        else:\n",
    "            final_df=pd.merge(final_df,group,on=['GeoName','year'])\n",
    "        count=count+1\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pivot_df(df):\n",
    "    grouped_df=df.groupby(['Description'])\n",
    "    count=0\n",
    "    for name, group in grouped_df:\n",
    "        group=group.drop('Description',axis=1)\n",
    "        group.columns=['GeoName','year',name]\n",
    "        if count==0:\n",
    "            final_df=group\n",
    "        else:\n",
    "            final_df=pd.merge(final_df,group,on=['GeoName','year'])\n",
    "        count=count+1\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pce_all_year=pivot_pc_df(melted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_df.to_csv('pce_all_year.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clean personal income data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variable_list=[]\n",
    "data_list=['SA1_1929_2017.csv','SA51_1948_2017.csv']\n",
    "data_path='C:/Users/ttodd/OneDrive/Desktop/capstone/personal_income/spi0318/'\n",
    "for i in os.listdir(data_path):\n",
    "    if i.endswith('ALL_AREAS.csv'):\n",
    "        data_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA1_1929_2017.csv',\n",
       " 'SA51_1948_2017.csv',\n",
       " 'SA25N_1998_2016__ALL_AREAS.csv',\n",
       " 'SA25_1969_2001__ALL_AREAS.csv',\n",
       " 'SA27N_1998_2016__ALL_AREAS.csv',\n",
       " 'SA27_1969_2001__ALL_AREAS.csv',\n",
       " 'SA30_1958_2016__ALL_AREAS.csv',\n",
       " 'SA35_1929_2016__ALL_AREAS.csv',\n",
       " 'SA40_1958_2016__ALL_AREAS.csv',\n",
       " 'SA45_1969_2016__ALL_AREAS.csv',\n",
       " 'SA4_1929_2017__ALL_AREAS.csv',\n",
       " 'SA50_1948_2016__ALL_AREAS.csv',\n",
       " 'SA5H_1929_1957__ALL_AREAS.csv',\n",
       " 'SA5N_1998_2017__ALL_AREAS.csv',\n",
       " 'SA5_1958_2001__ALL_AREAS.csv',\n",
       " 'SA6N_1998_2017__ALL_AREAS.csv',\n",
       " 'SA6_1958_2001__ALL_AREAS.csv',\n",
       " 'SA7H_1929_1957__ALL_AREAS.csv',\n",
       " 'SA7N_1998_2017__ALL_AREAS.csv',\n",
       " 'SA7_1958_2001__ALL_AREAS.csv']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_pi_df(temp_data): \n",
    "    temp_data=temp_data.drop_duplicates()\n",
    "    temp_data=temp_data.dropna(subset=['GeoName','Description'])\n",
    "    temp_data.replace(0,np.nan)\n",
    "    temp_data.replace(0.0,np.nan)\n",
    "    temp_data.dropna(thresh=2)\n",
    "    drop_column=temp_data['Description'].value_counts()\n",
    "    drop_column=list(drop_column[drop_column!=60].index)\n",
    "    temp_data=temp_data.loc[~temp_data['Description'].isin(drop_column),:]\n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result=pd.DataFrame({'state':state_list})\n",
    "df_count=0\n",
    "for i in data_list:\n",
    "    temp_data=pd.read_csv(data_path+i)\n",
    "    temp_data_column=temp_data.columns\n",
    "    temp_data_column=list(temp_data_column)\n",
    "    final_column_part1=['GeoName','Description']\n",
    "    final_column_part2=temp_data_column[7:]\n",
    "    final_column_part2=[x for x in final_column_part2 if x>='1997' and x<='2016']\n",
    "    final_column=final_column_part1+final_column_part2\n",
    "    if len(final_column)==22:\n",
    "        temp_data=temp_data.loc[:,final_column]\n",
    "        temp_data=clean_pi_df(temp_data)\n",
    "        temp_melted_df=temp_data.melt(id_vars=['Description','GeoName'])\n",
    "        temp_pi_df=pivot_df(temp_melted_df)\n",
    "        temp_column=temp_pi_df.columns\n",
    "        temp_pi_df['GeoName']=temp_pi_df['GeoName'].str.replace('\\*','')\n",
    "        cleaned_column=[re.sub('([0-9]{1}\\/)|(^\\s+)','',x) for x in temp_column]\n",
    "        temp_pi_df.columns=cleaned_column\n",
    "        #print(temp_pi_df.head(5))\n",
    "        if df_count==0:\n",
    "            final_result=temp_pi_df\n",
    "        else:\n",
    "            final_result=pd.merge(final_result,temp_pi_df,on=['GeoName','year'],how='inner',suffixes=('', '_y'))    \n",
    "        df_count+=1\n",
    "\n",
    "drop_columns=[x for x in final_result.columns if x.endswith('_y')]\n",
    "final_result=final_result.drop(drop_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result=final_result.loc[final_result['GeoName'].isin(state_list),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_result.to_csv('pi_all_year.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#electricity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elec=pd.read_csv('C:/Users/ttodd/OneDrive/Desktop/capstone/final data/Average_retail_price_of_electricity.csv',skiprows=4)\n",
    "#units is cents per killowatthour\n",
    "elec['GeoName'], elec['type'] = elec['description'].str.split(':', 1).str\n",
    "elec=elec.drop(['units','source key','description'],axis=1)\n",
    "elec=elec.dropna(subset=['type'])\n",
    "elec['GeoName']=elec['GeoName'].str.replace('\\s+$','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elec_state_list=[\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "  \"Connecticut\",\"Delaware\",'District Of Columbia',\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "  \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "  \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "  \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "  \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "  \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "  \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]\n",
    "\n",
    "elec=elec.loc[elec['GeoName'].isin(elec_state_list),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
